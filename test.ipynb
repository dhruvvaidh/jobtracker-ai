{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmail v1 service created successfully\n"
     ]
    }
   ],
   "source": [
    "from gmail_api import init_gmail_service, get_email_messages, get_email_message_details\n",
    "\n",
    "client_file = 'credentials.json'\n",
    "service = init_gmail_service(client_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '196756254e18feb8', 'threadId': '196756254e18feb8'},\n",
       " {'id': '19673f34c3c6c904', 'threadId': '19673f34c3c6c904'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'subject:\"application\" newer_than:1d -subject:\"credit card'\n",
    "emails_last_24hrs = get_email_messages(service, query=query, max_results=None)\n",
    "emails_last_24hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emails(messages):\n",
    "    body = []\n",
    "    emails = []\n",
    "    for msg in messages:\n",
    "        details = get_email_message_details(service,msg['id'])\n",
    "        if details:\n",
    "            print(details)\n",
    "            emails.append(details)\n",
    "\n",
    "    return emails, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 'Dhruv, your application was sent to Blockchain Council', 'sender': 'LinkedIn <jobs-noreply@linkedin.com>', 'recipients': 'Dhruv Vaidh <vaidhdhruv@gmail.com>', 'body': 'Your application was sent to Blockchain Council\\r\\n\\r\\nAI Intern (Paid)..\\r\\nBlockchain Council\\r\\nLos Angeles Metropolitan Area\\r\\nView job: https://www.linkedin.com/comm/jobs/view/4216015999/?trackingId=ezZvY8jPTuCnF%2FJVXa0bLA%3D%3D&refId=igDKKy%2BeSCKPrrlnI3jDow%3D%3D&lipi=urn%3Ali%3Apage%3Aemail_email_application_confirmation_with_nba_01%3BRTW8FCzdSTO%2Fmm%2FJs8EGdw%3D%3D&midToken=AQG8JIxNcU-3AQ&midSig=2gn2iAefEaZHI1&trk=eml-email_application_confirmation_with_nba_01-job_card-0-view_job&trkEmail=eml-email_application_confirmation_with_nba_01-job_card-0-view_job-null-d7ric0~m9z48v78~on-null-null&eid=d7ric0-m9z48v78-on&otpToken=MTUwYzE3ZTExMjJmYzljM2I2MjQwNGVkNDIxYmUwYjY4OWNlZDk0ODljYTg4NzYxNzljNzAwNjY0ZTVkNWNmMmYzZDNkZmE3MWFkNWRjODk0NTgxZjFmOWE3ODBiNjVmMjBkYjM1Yjg2YTk2OGU4ZWZhMGM2OCwxLDE%3D\\r\\n\\r\\n---------------------------------------------------------\\r\\n  \\r\\nApplied on April 27, 2025----------------------------------------------------------------\\r\\n        Now, take these next steps for more success\\r\\n\\r\\n\\r\\n\\r\\nView similar jobs you may be interested in\\r\\n            \\r\\nJunior AI Engineer\\r\\nTieTalent\\r\\nDurham, NC\\r\\nView job: https://www.linkedin.com/comm/jobs/view/4218135730/?trackingId=fUKQqWg3SDeri3vsHynOOA%3D%3D&refId=7%2FqiRUoHQvuuojd7w1Dmaw%3D%3D&lipi=urn%3Ali%3Apage%3Aemail_email_application_confirmation_with_nba_01%3BRTW8FCzdSTO%2Fmm%2FJs8EGdw%3D%3D&midToken=AQG8JIxNcU-3AQ&midSig=2gn2iAefEaZHI1&trk=eml-email_application_confirmation_with_nba_01-job_card-0-view_job&trkEmail=eml-email_application_confirmation_with_nba_01-job_card-0-view_job-null-d7ric0~m9z48v78~on-null-null&eid=d7ric0-m9z48v78-on&otpToken=MTUwYzE3ZTExMjJmYzljM2I2MjQwNGVkNDIxYmUwYjY4OWNlZDk0ODljYTg4NzYxNzljNzAwNjY0ZTVkNWNmMmYzZDNkZmE3MWFkNWRjODk0NTgxZjFmOWE3ODBiNjVmMjBkYjM1Yjg2YTk2OGU4ZWZhMGM2OCwxLDE%3D\\r\\n\\r\\n---------------------------------------------------------\\r\\n  \\r\\n            \\r\\nSoftware Engineering Intern\\r\\nAccompany Health\\r\\nUnited States\\r\\nView job: https://www.linkedin.com/comm/jobs/view/4214990453/?trackingId=7BMrQMBVSV23SrNgRxR4mA%3D%3D&refId=jqO9pGMGRXiHFUC%2FynS2Tg%3D%3D&lipi=urn%3Ali%3Apage%3Aemail_email_application_confirmation_with_nba_01%3BRTW8FCzdSTO%2Fmm%2FJs8EGdw%3D%3D&midToken=AQG8JIxNcU-3AQ&midSig=2gn2iAefEaZHI1&trk=eml-email_application_confirmation_with_nba_01-job_card-0-view_job&trkEmail=eml-email_application_confirmation_with_nba_01-job_card-0-view_job-null-d7ric0~m9z48v78~on-null-null&eid=d7ric0-m9z48v78-on&otpToken=MTUwYzE3ZTExMjJmYzljM2I2MjQwNGVkNDIxYmUwYjY4OWNlZDk0ODljYTg4NzYxNzljNzAwNjY0ZTVkNWNmMmYzZDNkZmE3MWFkNWRjODk0NTgxZjFmOWE3ODBiNjVmMjBkYjM1Yjg2YTk2OGU4ZWZhMGM2OCwxLDE%3D\\r\\n\\r\\n---------------------------------------------------------\\r\\n  \\r\\n            \\r\\nSoftware Engineer Intern\\r\\nBending Spoons\\r\\nLondon\\r\\nView job: https://www.linkedin.com/comm/jobs/view/4215504922/?trackingId=57jyX7i6R46va%2F9fLWHGHQ%3D%3D&refId=VKneN2AfRd2mS4XNzj2U1A%3D%3D&lipi=urn%3Ali%3Apage%3Aemail_email_application_confirmation_with_nba_01%3BRTW8FCzdSTO%2Fmm%2FJs8EGdw%3D%3D&midToken=AQG8JIxNcU-3AQ&midSig=2gn2iAefEaZHI1&trk=eml-email_application_confirmation_with_nba_01-job_card-0-view_job&trkEmail=eml-email_application_confirmation_with_nba_01-job_card-0-view_job-null-d7ric0~m9z48v78~on-null-null&eid=d7ric0-m9z48v78-on&otpToken=MTUwYzE3ZTExMjJmYzljM2I2MjQwNGVkNDIxYmUwYjY4OWNlZDk0ODljYTg4NzYxNzljNzAwNjY0ZTVkNWNmMmYzZDNkZmE3MWFkNWRjODk0NTgxZjFmOWE3ODBiNjVmMjBkYjM1Yjg2YTk2OGU4ZWZhMGM2OCwxLDE%3D\\r\\n\\r\\n---------------------------------------------------------\\r\\n  \\r\\n\\r\\n      \\r\\n\\r\\n----------------------------------------\\r\\n\\r\\nThis email was intended for Dhruv Vaidh (Looking for Internship/ Full Time Opportunities in Machine Learning, Generative AI, Data Science| MS in Data Science @RIT ‘25 | BTech CS @VIT Vellore ‘23)\\r\\nLearn why we included this: https://www.linkedin.com/help/linkedin/answer/4788?lang=en&lipi=urn%3Ali%3Apage%3Aemail_email_application_confirmation_with_nba_01%3BRTW8FCzdSTO%2Fmm%2FJs8EGdw%3D%3D&midToken=AQG8JIxNcU-3AQ&midSig=2gn2iAefEaZHI1&trk=eml-email_application_confirmation_with_nba_01-SecurityHelp-0-textfooterglimmer&trkEmail=eml-email_application_confirmation_with_nba_01-SecurityHelp-0-textfooterglimmer-null-d7ric0~m9z48v78~on-null-null&eid=d7ric0-m9z48v78-on&otpToken=MTUwYzE3ZTExMjJmYzljM2I2MjQwNGVkNDIxYmUwYjY4OWNlZDk0ODljYTg4NzYxNzljNzAwNjY0ZTVkNWNmMmYzZDNkZmE3MWFkNWRjODk0NTgxZjFmOWE3ODBiNjVmMjBkYjM1Yjg2YTk2OGU4ZWZhMGM2OCwxLDE%3D\\r\\nYou are receiving LinkedIn notification emails.\\r\\n\\r\\nUnsubscribe: https://www.linkedin.com/comm/psettings/email-unsubscribe?lipi=urn%3Ali%3Apage%3Aemail_email_application_confirmation_with_nba_01%3BRTW8FCzdSTO%2Fmm%2FJs8EGdw%3D%3D&midToken=AQG8JIxNcU-3AQ&midSig=2gn2iAefEaZHI1&trk=eml-email_application_confirmation_with_nba_01-unsubscribe-0-textfooterglimmer&trkEmail=eml-email_application_confirmation_with_nba_01-unsubscribe-0-textfooterglimmer-null-d7ric0~m9z48v78~on-null-null&eid=d7ric0-m9z48v78-on&loid=AQHsNS_w6-gVgQAAAZZ1YlBWCFHqdbBRxtC9LLzBut6o_kyVGtvf85FiI9vXXJ6xV5dQalAqX6aMhAj5fSG_YIag4kq4GQe84xLTS_0G0sICiP1I-2Y\\r\\nHelp: https://www.linkedin.com/help/linkedin/answer/67?lang=en&lipi=urn%3Ali%3Apage%3Aemail_email_application_confirmation_with_nba_01%3BRTW8FCzdSTO%2Fmm%2FJs8EGdw%3D%3D&midToken=AQG8JIxNcU-3AQ&midSig=2gn2iAefEaZHI1&trk=eml-email_application_confirmation_with_nba_01-help-0-textfooterglimmer&trkEmail=eml-email_application_confirmation_with_nba_01-help-0-textfooterglimmer-null-d7ric0~m9z48v78~on-null-null&eid=d7ric0-m9z48v78-on&otpToken=MTUwYzE3ZTExMjJmYzljM2I2MjQwNGVkNDIxYmUwYjY4OWNlZDk0ODljYTg4NzYxNzljNzAwNjY0ZTVkNWNmMmYzZDNkZmE3MWFkNWRjODk0NTgxZjFmOWE3ODBiNjVmMjBkYjM1Yjg2YTk2OGU4ZWZhMGM2OCwxLDE%3D\\r\\n\\r\\n© 2025 LinkedIn Corporation, 1zwnj000 West Maude Avenue, Sunnyvale, CA 94085.\\r\\nLinkedIn and the LinkedIn logo are registered trademarks of LinkedIn.', 'snippet': 'Your application was sent to Blockchain Council ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏ ͏', 'has_attachments': False, 'date': 'Sun, 27 Apr 2025 03:55:00 +0000 (UTC)', 'star': False, 'label': 'UNREAD, CATEGORY_UPDATES, INBOX'}\n",
      "{'subject': '[GitHub] A third-party OAuth application has been added to your account', 'sender': 'GitHub <noreply@github.com>', 'recipients': 'Dhruv Vaidh <vaidhdhruv@gmail.com>', 'body': 'Hey dhruvvaidh!\\r\\n\\r\\nA third-party OAuth application (Devpost) with user:email scopes was recently authorized to access your account.\\r\\nVisit https://github.com/settings/connections/applications/1db61ab3609315893031 for more information.\\r\\n\\r\\nTo see this and other security events for your account, visit https://github.com/settings/security-log\\r\\n\\r\\nIf you run into problems, please contact support by visiting https://github.com/contact\\r\\n\\r\\nThanks,\\r\\nThe GitHub Team\\r\\n\\r\\n', 'snippet': 'Hey dhruvvaidh! A third-party OAuth application (Devpost) with user:email scopes was recently authorized to access your account. Visit https://github.com/settings/connections/applications/', 'has_attachments': False, 'date': 'Sat, 26 Apr 2025 14:14:06 -0700', 'star': False, 'label': 'UNREAD, CATEGORY_UPDATES, INBOX'}\n"
     ]
    }
   ],
   "source": [
    "emails = get_emails(emails_last_24hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the system and human message templates for email analysis\n",
    "system_message_template = \"\"\"\n",
    "You are an assistant that analyzes whether a given email is a job application email.  \n",
    "- If it is a job application email, extract the following and present them in a JSON object:  \n",
    "  1. “company_name”  \n",
    "  2. “job_title”  \n",
    "  3. “application_status” (Applied, received, rejected, interview invitation, etc.)  \n",
    "  4. “important_dates” (list of any dates mentioned)  \n",
    "  5. “action_items” (list of any required follow-up tasks)  \n",
    "\n",
    "- If it is NOT a job application email, respond with:  \n",
    "None\n",
    "\"\"\"\n",
    "\n",
    "human_message_template = \"\"\"\n",
    "Analyze the following email:\n",
    "\n",
    "{email_body}\n",
    "\"\"\"\n",
    "# Create message templates that will be used in the ChatPromptTemplate in the next cell\n",
    "system_message = SystemMessage(content=system_message_template)\n",
    "human_message = HumanMessage(content=human_message_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid template: content='\\nYou are an assistant that analyzes whether a given email is a job application email.  \\n- If it is a job application email, extract the following and present them in a JSON object:  \\n  1. “company_name”  \\n  2. “job_title”  \\n  3. “application_status” (Applied, received, rejected, interview invitation, etc.)  \\n  4. “important_dates” (list of any dates mentioned)  \\n  5. “action_items” (list of any required follow-up tasks)  \\n\\n- If it is NOT a job application email, respond with:  \\nNone\\n' additional_kwargs={} response_metadata={}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m----> 4\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[43mChatPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_message\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m      9\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     12\u001b[0m prompt_value \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mformat_prompt(email_body \u001b[38;5;241m=\u001b[39m emails[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1005\u001b[0m, in \u001b[0;36mChatPromptTemplate.__init__\u001b[0;34m(self, messages, template_format, **kwargs)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    953\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    957\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \n\u001b[1;32m    960\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \n\u001b[1;32m   1003\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 1005\u001b[0m         \u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m   1006\u001b[0m     ]\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     input_vars: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1481\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message, template_format)\u001b[0m\n\u001b[1;32m   1479\u001b[0m message_type_str, template \u001b[38;5;241m=\u001b[39m message\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message_type_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1481\u001b[0m     _message \u001b[38;5;241m=\u001b[39m \u001b[43m_create_template_from_message_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_type_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1485\u001b[0m     _message \u001b[38;5;241m=\u001b[39m message_type_str(\n\u001b[1;32m   1486\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m   1487\u001b[0m             cast(\u001b[38;5;28mstr\u001b[39m, template), template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[1;32m   1488\u001b[0m         )\n\u001b[1;32m   1489\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1388\u001b[0m, in \u001b[0;36m_create_template_from_message_type\u001b[0;34m(message_type, template, template_format)\u001b[0m\n\u001b[1;32m   1384\u001b[0m     message \u001b[38;5;241m=\u001b[39m AIMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m   1385\u001b[0m         cast(\u001b[38;5;28mstr\u001b[39m, template), template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[1;32m   1386\u001b[0m     )\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m message_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1388\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mSystemMessagePromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m message_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplaceholder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(template, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:583\u001b[0m, in \u001b[0;36m_StringImageMessagePromptTemplate.from_template\u001b[0;34m(cls, template, template_format, partial_variables, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid template: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid template: content='\\nYou are an assistant that analyzes whether a given email is a job application email.  \\n- If it is a job application email, extract the following and present them in a JSON object:  \\n  1. “company_name”  \\n  2. “job_title”  \\n  3. “application_status” (Applied, received, rejected, interview invitation, etc.)  \\n  4. “important_dates” (list of any dates mentioned)  \\n  5. “action_items” (list of any required follow-up tasks)  \\n\\n- If it is NOT a job application email, respond with:  \\nNone\\n' additional_kwargs={} response_metadata={}"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", system_message_template),\n",
    "    (\"human\", human_message_template)])\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.2)\n",
    "\n",
    "prompt_value = template.format_prompt(email_body = emails[0])\n",
    "messages     = prompt_value.to_messages()\n",
    "response     = llm(messages=messages)\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/6n5wfp6j7gb74y_w3dymgdhc0000gn/T/ipykernel_75224/4176603190.py:66: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company_name': 'Blockchain Council', 'job_title': 'AI Intern', 'application_status': 'Applied', 'important_dates': ['April 27, 2025'], 'action_items': ['Let me know next steps']}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def extract_application_info(raw_response: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Given the LLM's raw response, return a Python dict if it contains JSON,\n",
    "    or None if the response is exactly \"None\" (case-insensitive).\n",
    "    \"\"\"\n",
    "    text = raw_response.strip()\n",
    "    # strip markdown code fences\n",
    "    text = re.sub(r'^```(?:json)?\\s*', '', text)\n",
    "    text = re.sub(r'\\s*```$', '', text)\n",
    "    \n",
    "    if text.lower() == 'none':\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # fallback: grab the first {...} block\n",
    "        m = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "        if m:\n",
    "            try:\n",
    "                return json.loads(m.group())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        raise ValueError(f\"Could not parse JSON from response: {raw_response!r}\")\n",
    "\n",
    "\n",
    "def extract_emails(emails):\n",
    "    # system + human templates\n",
    "    system_message_template = \"\"\"\n",
    "    You are an assistant that analyzes whether a given email is a job application email.  \n",
    "    - If it is a job application email, extract the following and present them in a JSON object:  \n",
    "      1. “company_name”  \n",
    "      2. “job_title”  \n",
    "      3. “application_status” (Applied, received, rejected, interview invitation, etc.)  \n",
    "      4. “important_dates” (list of any dates mentioned)  \n",
    "      5. “action_items” (list of any required follow-up tasks)  \n",
    "\n",
    "    - If it is NOT a job application email, respond with:\n",
    "      None\n",
    "    \"\"\"\n",
    "\n",
    "    human_message_template = \"\"\"\n",
    "    Analyze the following email:\n",
    "\n",
    "    {email_body}\n",
    "    \"\"\"\n",
    "\n",
    "    template = ChatPromptTemplate([\n",
    "        (\"system\", system_message_template),\n",
    "        (\"human\", human_message_template)\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o\",\n",
    "        temperature=0.2\n",
    "    )\n",
    "    data = []\n",
    "    for email in emails:\n",
    "        prompt_value = template.format_prompt(email_body=email)\n",
    "        messages     = prompt_value.to_messages()\n",
    "        response     = llm(messages=messages)\n",
    "        \n",
    "        # Clean & parse the LLM's output\n",
    "        parsed = extract_application_info(response.content)\n",
    "        data.append(parsed)\n",
    "        print(parsed)         # dict or None\n",
    "        print(type(parsed))   # <class 'dict'> or <class 'NoneType'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company_name': 'Blockchain Council', 'job_title': 'AI Intern (Paid)', 'application_status': 'Applied', 'important_dates': ['April 27, 2025'], 'action_items': []}\n",
      "<class 'dict'>\n",
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "extract_emails(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
